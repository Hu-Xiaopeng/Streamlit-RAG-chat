# Streamlit-RAG-chat
ğŸš€ A local RAG chatbot powered by llama-cpp-python ğŸ¦™

# ğŸ¤– Chat with RAG locally

é¦–å…ˆï¼Œç¡®ä¿æ‚¨çš„ç¯å¢ƒä¸­å®‰è£…äº†å¿…è¦çš„PythonåŒ…ã€‚è¿™é‡Œæ˜¯ä¸€ä¸ªæ¨èçš„ç¯å¢ƒé…ç½®ï¼š

bash:
    conda create -n rag-env python=3.11
    conda activate rag-env
    pip install -r requirements.txt  

model path:
    åœ¨ä»£ç çš„ `PRESET_EMBED_MODELS` å’Œ `PRESET_LLM_MODELS` ä¸­å¡«å…¥éœ€è¦ä½¿ç”¨çš„æ¨¡å‹

Usage:
    1.è¿è¡Œè„šæœ¬æ–‡ä»¶ï¼š
        åœ¨ç»ˆç«¯ä¸­æ‰§è¡Œ `streamlit run rag_demo.py`
    2.åœ¨æµè§ˆå™¨ä¸­æ‰“å¼€æ˜¾ç¤ºçš„æœ¬åœ°URLï¼Œå³å¯å¼€å§‹ä¸å›¾åƒè¿›è¡Œäº¤äº’ã€‚
    3.å…³é—­è„šæœ¬æ–‡ä»¶ï¼š
        åœ¨ç»ˆç«¯ä¸­æŒ‰ä¸‹ `Ctrl + C`